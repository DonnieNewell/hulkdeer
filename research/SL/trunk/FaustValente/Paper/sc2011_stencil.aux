\relax 
\citation{li}
\citation{CUDA1,CUDA2}
\citation{OpenCL}
\citation{OpenMP}
\citation{pthreads}
\citation{meng}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{li}
\@writefile{toc}{\contentsline {section}{\numberline {2}SL System Organization}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Iterative Stencil Loops: Terms \& Background}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SL System Diagram showing information flow in SL. The SL source is combined by the SL compiler with the appropriate optimized back-end template. The resultant generated subroutine for the ISL calculation is called by the rest of the user's application code.}}{2}}
\newlabel{fig:SysOrg}{{1}{2}}
\citation{meng}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (a) For a single tile in a 2D matrix, the number of valid calculated values decreases with each additional time interval between synchronization events. After 4 time steps, only the inner most rectangle of $n$ values are valid. (b) Two adjacent tiles shown from the plane of the 2D array with time in the vertical dimension. In the first time step (bottom) there is substantial overlap in the ghost zones in order to have the resultant valid values abut after 4 time steps (top).}}{3}}
\newlabel{fig:trapezoid}{{2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The {\tt  hotspot.sl} stencil language file. This example shows a 2D stencil calculation where each cell value is based on the values of that cell's immediate neighbors. The read-only data is interpreted as a 2D matrix in row-major order which indicates that some areas of the chip inherently run hotter then other areas.}}{3}}
\newlabel{fig:hotspot}{{3}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Stencil Language Definition}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Syntax}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Content}{3}}
\citation{CUDA1,CUDA2}
\citation{Fermi}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Read Only Data}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Stencil Language Compiler}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Generated CUDA Code}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}CUDA Architecture Overview}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces NVIDIA GPU Diagram. The CPU control thread launches a kernel with many threads per thread block. Each thread block is assigned to a Multiprocessor (PE) containing 8 scalar processing elements and a local shared memory. The Device Memory is global to all thread blocks; in pre-Fermi GPUs it was uncached.}}{5}}
\newlabel{fig:CUDAOrg}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}SL CUDA Template}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Pyramid Height Calculation}{5}}
\citation{Mashey}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Modification of Meng and Skadron Model}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experimental Results}{6}}
\newlabel{sec:results}{{7}{6}}
\citation{hotspot}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}\em  ``Pathfinder''}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}\em  ``HotSpot''}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Fermi runtimes for the Pathfinder 1D application versus PH. The lowest portion of the curves are very flat. Therefore, even though our model did not pick the best PH for any data set size, the performance was near optimal}}{7}}
\newlabel{fig:pathfinderTimes}{{5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Fermi runtimes for the HotSpot 2D stencil application versus PH. As can be seen, the curve is bowl shape with a minimum at PH 2. The effect is more pronounced with greater data set sizes. Our optimizer picked the correct PH of 2 for all these data sets.}}{7}}
\newlabel{fig:hotspotTimes}{{6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}\em  ``Plate''}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Fermi runtimes for the Cell 3D stencil application versus PH. The curve shows that a PH of 3 or 4 is a very bad choice. While the values for 1 and 2 are slightly compressed in the graph, the optimal PH is in fact 1 for all data sets.}}{8}}
\newlabel{fig:cellTimes}{{7}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}\em  ``Cell''}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Model Comparisons}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Fermi runtimes for HotSpot versus normalized runtimes predicted by the Model for PHs from 1 to 6. While the shape of the model curve does not precisely match that of the measured runtimes, the model accurately predicts an optimal PH of two.}}{8}}
\newlabel{fig:modelvsactual}{{8}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Comparison to Na\"{i}ve CUDA code}{8}}
\citation{li}
\citation{cm2}
\citation{ypnos}
\citation{kamil}
\citation{AutoTuning}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Runtimes for the SL optimized code for the four applications in Section\nobreakspace  {}7\hbox {}, plus two new versions of Plate. Runtimes are also shown for a na\"{i}ve CUDA implementation, along with a comparison relative to SL optimized code. For applications with large amounts of either temporal or spatial locality, the SL generated code far outperforms the na\"{i}ve code. For other applications, the difference is more modest. Data are listed for Fermi, on the top of the table, and Tesla, on the bottom. Fermi's larger block size results in higher optimal PH for Plate, PlateHalo, and Plate++ due to the larger tile sizes. The inclusion of a cache on Fermi also results in a lower relative improvement of SL optimized code versus na\"{i}ve for applications with large amounts of temporal or spatial locality. }}{9}}
\newlabel{fig:table}{{1}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Related Work}{9}}
\citation{Micikevicius}
\citation{volkov}
\citation{openmp2gpu}
\citation{cudalite}
\citation{Ryoo}
\bibstyle{plain}
\bibdata{PPoPP-report}
\bibcite{cm2}{1}
\bibcite{OpenMP}{2}
\bibcite{AutoTuning}{3}
\bibcite{kamil}{4}
\bibcite{openmp2gpu}{5}
\bibcite{li}{6}
\bibcite{CUDA1}{7}
\bibcite{Mashey}{8}
\bibcite{meng}{9}
\bibcite{Micikevicius}{10}
\@writefile{toc}{\contentsline {section}{\numberline {9}Conclusions and Future Directions}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {10}References}{10}}
\bibcite{pthreads}{11}
\bibcite{Fermi}{12}
\bibcite{CUDA2}{13}
\bibcite{ypnos}{14}
\bibcite{Ryoo}{15}
\bibcite{hotspot}{16}
\bibcite{OpenCL}{17}
\bibcite{cudalite}{18}
\bibcite{volkov}{19}
