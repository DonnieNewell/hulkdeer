#include "slmpi.h"
#include <stdio.h>
#include <stdlib.h>

#define DTYPE @DataType@

DTYPE * inputPtr;

// Macro to get data value.
#define get(xarg)(GetInputValue(input_size, inputPtr, ((int)((blockDim.x * blockIdx.x) + threadIdx.x)) + xarg))

// Macro to read global read only data from within CellValue code.
#define read(offset)(ro_data[offset])

#if EdgeValue
DTYPE EdgeValue(dim3 input_size, int x, DTYPE value)
{
@EdgeValue@
}
#endif

// Take care to only read global memory is no EdgeValue is specified.
DTYPE GetInputValue(dim3 input_size, DTYPE *data, int x)
{
    int ex, inside;
    ex = x;
    if (ex < 0) ex = 0;
    if (ex >= input_size.x) ex = input_size.x-1;
    inside = ((x == ex));
    if (inside) return data[x];
    DTYPE retval;
    int edgeComp = 0;
#if EdgeValue
    if (!inside)
    {
        retval = EdgeValue(input_size, x, value @ScalarVariableNames@);
        edgeComp = 1;
    }
#endif
    if (!edgeComp) retval = data[ex];
    return retval;
}

DTYPE CellValue(dim3 input_size, int iteration, int x, DTYPE *ro_data
                           @ScalarVariables@)
{
@CellValue@
}

/**
 * Each thread runs this kernel to calculate the value at one particular
 * cell in one particular iteration.
 */

// We need to declare it C style naming.
// This avoids name mangling and allows us to get attributes about the kernel call from Cuda.
// Its possible to do this with a C++ interface, but that will only run on certain devices.
// This technique is older and therefore more reliable across Cuda devices.
extern "C" {
void @FunctionName@Kernel(dim3 input_size, int iter, 
                          DTYPE *input, DTYPE *output, 
                          DTYPE *ro_data
                          @ScalarVariables@);
    }

void @FunctionName@Kernel(dim3 input_size, int iter, 
                          DTYPE *input, DTYPE *output, 
                          DTYPE *ro_data
                          @ScalarVariables@)
{
    if (threadIdx.x == 0) inputPtr = input;

    int bx, x;
    DTYPE value;

    // bx is the location in the input of the left of this block.
    bx = blockIdx.x * blockDim.x;
    // x is the location in the input of this thread.
    x = bx + threadIdx.x;
    // Make sure we are not output the data size.
    if (x >= input_size.x) return;

    value = CellValue(input_size, iter, x, ro_data
                          @ScalarVariableNames@);

    output[x] = value;
}

/**
 * Store data between calls to SetData() and run().
 * This is basically a hack.
 */
static DTYPE *global_ro_data = NULL;

/**
 * Function exported to do the entire stencil computation.
 */
void @FunctionName@(DTYPE *host_data, int x_max, int iterations
                    @ScalarVariables@)
{
    // User-specific parameters
  dim3 input_size(x_max);
  dim3 stencil_size@StencilSize@;
  int size, rank;

  extern int g_argc;
  extern char *g_argv[];

  MPI_Init(&g_argc, &g_argv);

  MPI_Comm_size(MPI_COMM_WORLD, &size);
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);

  // Host to device
  DTYPE *device_input, *device_output;
  int num_bytes = input_size.x * sizeof(DTYPE);
  cudaMalloc((void **) &device_input, num_bytes);
  cudaMalloc((void **) &device_output, num_bytes);
  cudaMemcpy(device_input, host_data, num_bytes, cudaMemcpyHostToDevice);

  // Setup the structure that holds parameters for the application.
  // And from that, get the block size.
  char * KernelName = "@FunctionName@Kernel";
  dim3 tile_size = initSAProps(@NumDimensions@, input_size, stencil_size, iterations, sizeof(DTYPE), KernelName);

  dim3 grid_dims;
  filldim3(&grid_dims, div_ceil(input_size.x, tile_size.x));

/////////////////////////////////////////////////////////////////////////////////////
// Start of code to gather statistics to hone model.  Remove in final version.
////////////////////////////////////////////////////////////////////////////////////

/////////////////////////////////////////////////////////////////////////////////////
// End of code to gather statistics to hone model.  Remove in final version.
////////////////////////////////////////////////////////////////////////////////////

#ifdef STATISTICS
    fprintf(stderr, "***********************************Start of a new Run****************************************\n");
    fprintf(stderr, "Data Size=%d, Tile Size=%d Iteration Count=%d\n", input_size.x, tile_size.x, iterations);
    struct timeval starttime, endtime;
    unsigned int usec2;
    gettimeofday(&starttime, NULL);                                       
#endif

    // Run computation
    for (int iter = 1; iter <= iterations; iter += 1)
    {
        @FunctionName@Kernel<<< grid_dims, tile_size >>>(
            input_size, iter, device_input, device_output,
            global_ro_data
            @ScalarVariableNames@);
#ifdef STATISTICS
        /// TEMPORARY HACK to get some debug info to make sure the kernel call succeeds.
        /// Should we leave it in, or take it out?
        cudaError_t foo = cudaGetLastError();
        if (foo != cudaSuccess) fprintf(stderr, "%s\n", cudaGetErrorString(foo));
#endif
        DTYPE *temp = device_input;
        device_input = device_output;
        device_output = temp;
    }

#ifdef STATISTICS
    // Synch the threads to make sure everything is done before taking a timing.
    CUDA_SAFE_THREAD_SYNC();
    gettimeofday(&endtime, NULL);                                       
    usec2 = ((endtime.tv_sec - starttime.tv_sec) * 1000000 +             
             (endtime.tv_usec - starttime.tv_usec));                       
    fprintf(stderr, "Actual total time=%u\n", usec2);
#endif

    // Device to host
    cudaMemcpy(host_data, device_input, num_bytes, cudaMemcpyDeviceToHost);
    cudaFree(device_input);
    cudaFree(device_output);
    if (global_ro_data != NULL)
    {
        cudaFree(global_ro_data);
        global_ro_data = NULL;
    }
}

/**
 * Store unnamed data on device.
 */
void @FunctionName@SetData(DTYPE *host_data, int num_elements)
{
    // TEMPORARY.
    // If we want to set the cuda device number, it must be here before we call any other cuda functions.
    // cudaSetDevice(1);

    int num_bytes = sizeof(DTYPE) * num_elements;
    cudaMalloc((void **) &global_ro_data, num_bytes);
    cudaMemcpy(global_ro_data, host_data, num_bytes, cudaMemcpyHostToDevice);
}
